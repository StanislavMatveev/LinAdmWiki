# Тесты кластера Corosync + Pacemaker

*[[tests|<- Назад]]*

*[[index|<- На главную]]*
***
## Данные

**Исходные данные:**

- Две виртуальные машины под управлением Ubuntu 20.04.
- Кластер из Corosync+Pacemaker с настройками через pcm.
- На виртуальных машинах работает сервис nginx, которые раздает статическое содержимое.

**Цели:**

- Опытным путем подобрать наиболее оптимальные характеристики для бесперебойной работы кластера.

## Нагрузка ЦПУ активной ноды до предела

**Использовалось:**

- `stress -c 50`

**Результаты:**

- Ничего не изменилось.

**Использовалось:**

- `stress -c 100`

**Результаты:**

- Ничего не изменилось.

**Использовалось:**

- `stress -c 100 -m 5`
- Временной интервал 5 минут

**Результаты:**

- Ничего не изменилось.

**Использовалось:**

- `stress -c 1000`
- Временной интервал 1 минута

**Результаты:**

- `htop` завис и не смог подключить вторую ssh-сессию. =)
- Ничего не изменилось.

**Выводы:**

- Нагрузкой ЦПУ активной ноды не удалось добиться каких-то заметных результатов относящихся к кластеру.
- Возможно, если бы веб-сервер раздавал не просто статическое содержимое, а что-то более энергозатратное, то результат был бы иной.

## Выход из строя сети активной ноды

**Использовалось:**

- Отключение сетевого устройства активной ноды номер 1 через панель `proxmox`
- Временной интервал 30 секунд

**Результаты:**

- Главным стал другой узел кластера под номером 2. После включения ноды 1, нода 2 продолжила оставаться главной. Так же в `pcs status` показывает что была ошибка у ноды 1. После отключения ноды 2, нода 1 не стала главной, ресурсы на ней имеют статус `stopped`. После включения ноды 2, ничего не меняется. Ресурсы все остановлены, висит отображение ошибок для 1 и 2 ноды.
- Перезагрузка службы pacemaker на обоих узлах восстанавливает работу кластера.

**Использовалось:**

- `ifconfig eth0 down` на ноде 1

**Результаты:**

- Главным стал другой узел кластера под номером 2. После перезагрузки ноды 1, она вновь стала главной.

**Использовалось:**

- Скрипт `ip link set eth0 down; sleep 60; ip link set eth0 up` через `tmux` (чтобы скрипт продолжил выполняться после разрыва соединения) на ноде 1

**Результаты:**

- Главным стал другой узел кластера под номером 2. После включения скриптом сетевого интерфейса на ноде 1, нода 2 продолжила оставаться главной. В `pcs status` показывает, что была ошибка у ноды 1. Если отключить и включить ноду 2, повторяется ситуация с выключением сетевого интерфейса из первого теста.
- Перезагрузка службы pacemaker на обоих узлах восстанавливает работу кластера.

**Использовалось:**

- Цепочка команд, для достижения эффекта 20% потери пакетов

```bash
iptables -A INPUT -p tcp --dport 22 -j ACCEPT;
iptables -A OUTPUT -p tcp --dport 22 -j ACCEPT;
iptables -A INPUT -m statistic --mode random --probability 0.2 -j DROP;
iptables -A OUTPUT -m statistic --mode random --probability 0.2 -j DROP
```

**Результаты:**

- Из-за частой потери пакетов, ноды перестают видеть друг друга, т.е. в `pcs status` у каждой ноды, противоположная нода в статусе оффлайн. В связи с этим ресурсы активны на обеих нодах - происходит задвоение. В моменты когда пакеты кластера все-таки проходят, срабатывает pacemaker, он останавливает все ноды и включает только одну (это поведение называется `stop_start` и является действием по умолчанию для атрибута `multiple-active`).
- Доступ к nginx происходит по нескольким сценариям:
	1. Если кластер успел отправить сигнал, то доступ к nginx идет через 2 ноду, все будет работать нормально несмотря на задвоение (т.к. 1 ноду будет считать оффлайн).
	2. Если кластер не успел отправить сигнал или в момент когда пакеты кластера дошли и pacemaker устранил задвоение, и переключил все на 1 ноду, то доступ идет через 1 ноду, соответственно будет выводится то сайт, то ошибка. До тех пор пока пакеты кластера вновь не начнут проходить и он не попытается устранить проблемы.
- После устранения потери пакетов (в данном случае удалении правил), pacemaker все восстанавливает.

**Выводы:**

- В тестах с отключением сети, видно что при возникновении ошибки у ресурса ноды, она перестает работать до тех пор, пока эти ошибки не будут устранены, а записи о них сброшены (сброс командой, рестарт службы или машины). Данное поведение возникает только при использовании сети `knet` для 2-х узлов без полноценного кворума. *Решение:* использовать сеть `knet`, для более чем 2-х узлов, с полноценным кворумом или `udpu`, но на ней возникают свои проблемы (не видит отключения сети).
- В тесте с потерей пакетов, проблема возникает из-за попыток включить ноду которая все еще "сломана", что вызывает ряд проблем которые нарушают стабильность. Данную проблему может решить использование сети `knet` для более чем 2-х узлов с полноценным кворумом.

***